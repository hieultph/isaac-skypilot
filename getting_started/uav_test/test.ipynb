{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae49a1f5",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeba37b6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from gr00t.utils.misc import any_describe\n",
    "from gr00t.data.dataset import LeRobotSingleDataset\n",
    "from gr00t.data.dataset import ModalityConfig\n",
    "from gr00t.data.schema import EmbodimentTag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6d0e1c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import gr00t\n",
    "\n",
    "# REPO_PATH is the path of the pip install gr00t repo and one level up\n",
    "REPO_PATH = os.path.dirname(os.path.dirname(gr00t.__file__))\n",
    "DATA_PATH = os.path.join(REPO_PATH, \"demo_data/robot_sim.PickNPlace\")\n",
    "\n",
    "print(\"Loading dataset... from\", DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946aa238",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 2. modality configs\n",
    "modality_configs = {\n",
    "    \"video\": ModalityConfig(\n",
    "        delta_indices=[0],\n",
    "        modality_keys=[\"video.ego_view\"],\n",
    "    ),\n",
    "    \"state\": ModalityConfig(\n",
    "        delta_indices=[0],\n",
    "        modality_keys=[\n",
    "            \"state.left_arm\",\n",
    "            \"state.left_hand\",\n",
    "            \"state.left_leg\",\n",
    "            \"state.neck\",\n",
    "            \"state.right_arm\",\n",
    "            \"state.right_hand\",\n",
    "            \"state.right_leg\",\n",
    "            \"state.waist\",\n",
    "        ],\n",
    "    ),\n",
    "    \"action\": ModalityConfig(\n",
    "        delta_indices=[0],\n",
    "        modality_keys=[\n",
    "            \"action.left_hand\",\n",
    "            \"action.right_hand\",\n",
    "        ],\n",
    "    ),\n",
    "    \"language\": ModalityConfig(\n",
    "        delta_indices=[0],\n",
    "        modality_keys=[\"annotation.human.action.task_description\", \"annotation.human.validity\"],\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda6f5a1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 3. gr00t embodiment tag\n",
    "embodiment_tag = EmbodimentTag.UAV\n",
    "\n",
    "# load the dataset\n",
    "dataset = LeRobotSingleDataset(DATA_PATH, modality_configs,  embodiment_tag=embodiment_tag)\n",
    "\n",
    "print('\\n'*2)\n",
    "print(\"=\"*100)\n",
    "print(f\"{' Humanoid Dataset ':=^100}\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# print the 7th data point\n",
    "resp = dataset[7]\n",
    "any_describe(resp)\n",
    "print(resp.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586322ab",
   "metadata": {},
   "source": [
    "show image frame within the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc25d63",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# show img\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "images_list = []\n",
    "\n",
    "for i in range(100):\n",
    "    if i % 10 == 0:\n",
    "        resp = dataset[i]\n",
    "        img = resp[\"video.ego_view\"][0]\n",
    "        images_list.append(img)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 5, figsize=(20, 10))\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.imshow(images_list[i])\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(f\"Image {i}\")\n",
    "plt.tight_layout() # adjust the subplots to fit into the figure area.\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ed58c9",
   "metadata": {},
   "source": [
    "## Transform the data to LeRobot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2123e4ca",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from gr00t.data.transform.base import ComposedModalityTransform\n",
    "from gr00t.data.transform import VideoToTensor, VideoCrop, VideoResize, VideoColorJitter, VideoToNumpy\n",
    "from gr00t.data.transform.state_action import StateActionToTensor, StateActionTransform\n",
    "from gr00t.data.transform.concat import ConcatTransform\n",
    "\n",
    "\n",
    "video_modality = modality_configs[\"video\"]\n",
    "state_modality = modality_configs[\"state\"]\n",
    "action_modality = modality_configs[\"action\"]\n",
    "\n",
    "# select the transforms you want to apply to the data\n",
    "to_apply_transforms = ComposedModalityTransform(\n",
    "    transforms=[\n",
    "        # video transforms\n",
    "        VideoToTensor(apply_to=video_modality.modality_keys),\n",
    "        VideoCrop(apply_to=video_modality.modality_keys, scale=0.95),\n",
    "        VideoResize(apply_to=video_modality.modality_keys, height=224, width=224, interpolation=\"linear\"),\n",
    "        VideoColorJitter(apply_to=video_modality.modality_keys, brightness=0.3, contrast=0.4, saturation=0.5, hue=0.08),\n",
    "        VideoToNumpy(apply_to=video_modality.modality_keys),\n",
    "\n",
    "        # state transforms\n",
    "        StateActionToTensor(apply_to=state_modality.modality_keys),\n",
    "        StateActionTransform(apply_to=state_modality.modality_keys, normalization_modes={\n",
    "            key: \"min_max\" for key in state_modality.modality_keys\n",
    "        }),\n",
    "\n",
    "        # action transforms\n",
    "        StateActionToTensor(apply_to=action_modality.modality_keys),\n",
    "        StateActionTransform(apply_to=action_modality.modality_keys, normalization_modes={\n",
    "            key: \"min_max\" for key in action_modality.modality_keys\n",
    "        }),\n",
    "\n",
    "        # ConcatTransform\n",
    "        ConcatTransform(\n",
    "            video_concat_order=video_modality.modality_keys,\n",
    "            state_concat_order=state_modality.modality_keys,\n",
    "            action_concat_order=action_modality.modality_keys,\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db668905",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dataset = LeRobotSingleDataset(\n",
    "    DATA_PATH,\n",
    "    modality_configs,\n",
    "    transforms=to_apply_transforms,\n",
    "    embodiment_tag=embodiment_tag\n",
    ")\n",
    "\n",
    "# print the 7th data point\n",
    "resp = dataset[7]\n",
    "any_describe(resp)\n",
    "print(resp.keys())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
