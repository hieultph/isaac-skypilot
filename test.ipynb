{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae49a1f5",
   "metadata": {},
   "source": [
    "# UAV Quadcopter GR00T Adaptation Test\n",
    "\n",
    "This notebook tests the UAV quadcopter adaptation of the GR00T model.\n",
    "\n",
    "**Key Components:**\n",
    "- New UAV Embodiment Tag: `EmbodimentTag.UAV_QUADCOPTER`\n",
    "- UAV State Space: 13D (position, orientation, velocity, battery, GPS)\n",
    "- UAV Action Space: 9D (flight_control, velocity_command, gimbal)\n",
    "- Leverage pretrained VLM, retrain only diffusion action head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601bee3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import UAV-specific components\n",
    "from gr00t.utils.misc import any_describe\n",
    "from gr00t.data.dataset import LeRobotSingleDataset\n",
    "from gr00t.data.dataset import ModalityConfig\n",
    "from gr00t.data.embodiment_tags import EmbodimentTag\n",
    "from gr00t.experiment.data_config import UAVQuadcopterDataConfig\n",
    "\n",
    "# Test the new UAV embodiment tag\n",
    "print(\"Available embodiment tags:\")\n",
    "for tag in EmbodimentTag:\n",
    "    print(f\"  {tag.name}: {tag.value}\")\n",
    "\n",
    "print(f\"\\nUAV Quadcopter tag: {EmbodimentTag.UAV_QUADCOPTER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbfe0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import gr00t\n",
    "\n",
    "# Test UAV data configuration\n",
    "print(\"Testing UAV Quadcopter Data Configuration...\")\n",
    "\n",
    "# Initialize UAV config\n",
    "uav_config = UAVQuadcopterDataConfig()\n",
    "print(\"‚úì UAV config initialized\")\n",
    "\n",
    "# Get modality configs\n",
    "modality_configs = uav_config.modality_config()\n",
    "print(\"‚úì Modality configs generated\")\n",
    "\n",
    "print(\"\\nUAV Modality Keys:\")\n",
    "for modality_type, config in modality_configs.items():\n",
    "    print(f\"  {modality_type}: {config.modality_keys}\")\n",
    "\n",
    "# Test transforms\n",
    "transforms = uav_config.transform()\n",
    "print(\"‚úì UAV transforms configured\")\n",
    "\n",
    "print(f\"\\nTotal transforms: {len(transforms.transforms)}\")\n",
    "for i, transform in enumerate(transforms.transforms):\n",
    "    print(f\"  {i}: {transform.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98620bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test UAV-specific modality configurations\n",
    "print(\"UAV State and Action Space Definition:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nState Space (13D):\")\n",
    "state_keys = uav_config.state_keys\n",
    "for i, key in enumerate(state_keys):\n",
    "    if key == \"state.position\":\n",
    "        print(f\"  {key}: x, y, z (3 dims)\")\n",
    "    elif key == \"state.orientation\": \n",
    "        print(f\"  {key}: roll, pitch, yaw (3 dims)\")\n",
    "    elif key == \"state.velocity\":\n",
    "        print(f\"  {key}: vx, vy, vz (3 dims)\")\n",
    "    elif key == \"state.battery\":\n",
    "        print(f\"  {key}: battery level (1 dim)\")\n",
    "    elif key == \"state.gps\":\n",
    "        print(f\"  {key}: lat, lon, alt (3 dims)\")\n",
    "\n",
    "print(f\"\\nTotal state dimensions: 13\")\n",
    "\n",
    "print(\"\\nAction Space (9D):\")\n",
    "action_keys = uav_config.action_keys\n",
    "for i, key in enumerate(action_keys):\n",
    "    if key == \"action.flight_control\":\n",
    "        print(f\"  {key}: throttle, roll, pitch, yaw (4 dims)\")\n",
    "    elif key == \"action.velocity_command\":\n",
    "        print(f\"  {key}: vx, vy, vz (3 dims)\")\n",
    "    elif key == \"action.gimbal\":\n",
    "        print(f\"  {key}: gimbal_pitch, gimbal_yaw (2 dims)\")\n",
    "\n",
    "print(f\"\\nTotal action dimensions: 9\")\n",
    "\n",
    "print(\"\\nVideo Inputs:\")\n",
    "for key in uav_config.video_keys:\n",
    "    print(f\"  {key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda6f5a1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 3. gr00t embodiment tag\n",
    "embodiment_tag = EmbodimentTag.UAV\n",
    "\n",
    "# load the dataset\n",
    "dataset = LeRobotSingleDataset(DATA_PATH, modality_configs,  embodiment_tag=embodiment_tag)\n",
    "\n",
    "print('\\n'*2)\n",
    "print(\"=\"*100)\n",
    "print(f\"{' Humanoid Dataset ':=^100}\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# print the 7th data point\n",
    "resp = dataset[7]\n",
    "any_describe(resp)\n",
    "print(resp.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586322ab",
   "metadata": {},
   "source": [
    "show image frame within the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc25d63",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# show img\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "images_list = []\n",
    "\n",
    "for i in range(100):\n",
    "    if i % 10 == 0:\n",
    "        resp = dataset[i]\n",
    "        img = resp[\"video.ego_view\"][0]\n",
    "        images_list.append(img)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 5, figsize=(20, 10))\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.imshow(images_list[i])\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(f\"Image {i}\")\n",
    "plt.tight_layout() # adjust the subplots to fit into the figure area.\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ed58c9",
   "metadata": {},
   "source": [
    "## Transform the data to LeRobot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2123e4ca",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from gr00t.data.transform.base import ComposedModalityTransform\n",
    "from gr00t.data.transform import VideoToTensor, VideoCrop, VideoResize, VideoColorJitter, VideoToNumpy\n",
    "from gr00t.data.transform.state_action import StateActionToTensor, StateActionTransform\n",
    "from gr00t.data.transform.concat import ConcatTransform\n",
    "\n",
    "\n",
    "video_modality = modality_configs[\"video\"]\n",
    "state_modality = modality_configs[\"state\"]\n",
    "action_modality = modality_configs[\"action\"]\n",
    "\n",
    "# select the transforms you want to apply to the data\n",
    "to_apply_transforms = ComposedModalityTransform(\n",
    "    transforms=[\n",
    "        # video transforms\n",
    "        VideoToTensor(apply_to=video_modality.modality_keys),\n",
    "        VideoCrop(apply_to=video_modality.modality_keys, scale=0.95),\n",
    "        VideoResize(apply_to=video_modality.modality_keys, height=224, width=224, interpolation=\"linear\"),\n",
    "        VideoColorJitter(apply_to=video_modality.modality_keys, brightness=0.3, contrast=0.4, saturation=0.5, hue=0.08),\n",
    "        VideoToNumpy(apply_to=video_modality.modality_keys),\n",
    "\n",
    "        # state transforms\n",
    "        StateActionToTensor(apply_to=state_modality.modality_keys),\n",
    "        StateActionTransform(apply_to=state_modality.modality_keys, normalization_modes={\n",
    "            key: \"min_max\" for key in state_modality.modality_keys\n",
    "        }),\n",
    "\n",
    "        # action transforms\n",
    "        StateActionToTensor(apply_to=action_modality.modality_keys),\n",
    "        StateActionTransform(apply_to=action_modality.modality_keys, normalization_modes={\n",
    "            key: \"min_max\" for key in action_modality.modality_keys\n",
    "        }),\n",
    "\n",
    "        # ConcatTransform\n",
    "        ConcatTransform(\n",
    "            video_concat_order=video_modality.modality_keys,\n",
    "            state_concat_order=state_modality.modality_keys,\n",
    "            action_concat_order=action_modality.modality_keys,\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db668905",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dataset = LeRobotSingleDataset(\n",
    "    DATA_PATH,\n",
    "    modality_configs,\n",
    "    transforms=to_apply_transforms,\n",
    "    embodiment_tag=embodiment_tag\n",
    ")\n",
    "\n",
    "# print the 7th data point\n",
    "resp = dataset[7]\n",
    "any_describe(resp)\n",
    "print(resp.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c81b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mock UAV observation for testing\n",
    "print(\"\\nCreating Mock UAV Observation:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Mock UAV observation data\n",
    "mock_uav_observation = {\n",
    "    # Video feeds (would be actual camera data)\n",
    "    \"video.front_camera\": np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8),\n",
    "    \"video.gimbal_camera\": np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8),\n",
    "    \n",
    "    # UAV telemetry state (13D total)\n",
    "    \"state.position\": np.array([10.5, 5.2, 15.0], dtype=np.float32),  # x, y, z\n",
    "    \"state.orientation\": np.array([0.1, -0.05, 1.57], dtype=np.float32),  # roll, pitch, yaw\n",
    "    \"state.velocity\": np.array([2.0, 0.5, -0.1], dtype=np.float32),  # vx, vy, vz\n",
    "    \"state.battery\": np.array([85.5], dtype=np.float32),  # battery %\n",
    "    \"state.gps\": np.array([37.7749, -122.4194, 100.0], dtype=np.float32),  # lat, lon, alt\n",
    "    \n",
    "    # Task description\n",
    "    \"annotation.human.task_description\": \"Navigate to landing zone and perform precision landing\"\n",
    "}\n",
    "\n",
    "print(\"Mock observation keys:\")\n",
    "for key, value in mock_uav_observation.items():\n",
    "    if hasattr(value, 'shape'):\n",
    "        print(f\"  {key}: shape {value.shape}, dtype {value.dtype}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {type(value)}\")\n",
    "\n",
    "# Verify state dimensionality\n",
    "state_dims = 0\n",
    "for key in uav_config.state_keys:\n",
    "    if key in mock_uav_observation:\n",
    "        state_dims += len(mock_uav_observation[key])\n",
    "\n",
    "print(f\"\\nTotal state dimensions: {state_dims}\")\n",
    "print(\"‚úì UAV observation structure validated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa404e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate UAV action space\n",
    "print(\"\\nUAV Action Space Demonstration:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Mock UAV action (9D total)\n",
    "mock_uav_action = {\n",
    "    \"action.flight_control\": np.array([0.6, 0.1, -0.05, 0.2], dtype=np.float32),  # throttle, roll, pitch, yaw\n",
    "    \"action.velocity_command\": np.array([1.5, 0.3, -0.2], dtype=np.float32),      # vx, vy, vz\n",
    "    \"action.gimbal\": np.array([-0.1, 0.4], dtype=np.float32)                     # gimbal_pitch, gimbal_yaw\n",
    "}\n",
    "\n",
    "print(\"Mock UAV action:\")\n",
    "for key, value in mock_uav_action.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Verify action dimensionality  \n",
    "action_dims = 0\n",
    "for key in uav_config.action_keys:\n",
    "    if key in mock_uav_action:\n",
    "        action_dims += len(mock_uav_action[key])\n",
    "\n",
    "print(f\"\\nTotal action dimensions: {action_dims}\")\n",
    "\n",
    "# Interpret action components\n",
    "print(\"\\nAction Interpretation:\")\n",
    "flight_control = mock_uav_action[\"action.flight_control\"]\n",
    "print(f\"  Flight Control:\")\n",
    "print(f\"    Throttle: {flight_control[0]:.3f} (0=min, 1=max thrust)\")\n",
    "print(f\"    Roll:     {flight_control[1]:.3f} (rad, + = right roll)\")  \n",
    "print(f\"    Pitch:    {flight_control[2]:.3f} (rad, + = nose up)\")\n",
    "print(f\"    Yaw:      {flight_control[3]:.3f} (rad, + = clockwise)\")\n",
    "\n",
    "velocity_cmd = mock_uav_action[\"action.velocity_command\"]\n",
    "print(f\"  Velocity Command:\")\n",
    "print(f\"    Vx: {velocity_cmd[0]:.3f} m/s (forward)\")\n",
    "print(f\"    Vy: {velocity_cmd[1]:.3f} m/s (right)\")\n",
    "print(f\"    Vz: {velocity_cmd[2]:.3f} m/s (down)\")\n",
    "\n",
    "gimbal = mock_uav_action[\"action.gimbal\"]\n",
    "print(f\"  Gimbal Control:\")\n",
    "print(f\"    Pitch: {gimbal[0]:.3f} rad (+ = tilt down)\")\n",
    "print(f\"    Yaw:   {gimbal[1]:.3f} rad (+ = pan right)\")\n",
    "\n",
    "print(\"‚úì UAV action space validated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69510473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic UAV dataset for testing\n",
    "print(\"üöÅ Generating Synthetic UAV Landing Dataset\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Generate a small test dataset\n",
    "dataset_path = \"./demo_data/uav.Landing\"\n",
    "num_episodes = 10  # Small dataset for testing\n",
    "\n",
    "print(f\"Generating {num_episodes} episodes of UAV landing data...\")\n",
    "print(f\"Output path: {dataset_path}\")\n",
    "\n",
    "# Create the data generator inline for notebook use\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "class SimpleUAVDataGenerator:\n",
    "    \"\"\"Simplified UAV data generator for notebook use.\"\"\"\n",
    "    \n",
    "    def __init__(self, output_dir: str):\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.image_size = (480, 640, 3)\n",
    "        self.fps = 20\n",
    "        self.episode_length = 100  # 5 seconds\n",
    "        self.setup_directories()\n",
    "    \n",
    "    def setup_directories(self):\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        (self.output_dir / \"data\").mkdir(exist_ok=True)\n",
    "        (self.output_dir / \"meta\").mkdir(exist_ok=True)\n",
    "        (self.output_dir / \"videos\").mkdir(exist_ok=True)\n",
    "    \n",
    "    def generate_simple_episode(self, episode_idx: int):\n",
    "        \"\"\"Generate a simple landing episode.\"\"\"\n",
    "        # Simple linear descent trajectory\n",
    "        positions = []\n",
    "        velocities = []\n",
    "        orientations = []\n",
    "        \n",
    "        # Start at altitude, land at origin\n",
    "        start_alt = 20.0\n",
    "        for i in range(self.episode_length):\n",
    "            progress = i / self.episode_length\n",
    "            \n",
    "            # Linear descent\n",
    "            pos = np.array([\n",
    "                10 * (1 - progress),  # x: move towards origin\n",
    "                5 * (1 - progress),   # y: move towards origin  \n",
    "                start_alt * (1 - progress)  # z: descend to ground\n",
    "            ])\n",
    "            positions.append(pos)\n",
    "            \n",
    "            # Simple velocity\n",
    "            vel = np.array([-0.1, -0.05, -0.2])\n",
    "            velocities.append(vel)\n",
    "            \n",
    "            # Level orientation with small variations\n",
    "            orientation = np.array([\n",
    "                np.random.normal(0, 0.05),  # roll\n",
    "                np.random.normal(0, 0.05),  # pitch\n",
    "                0.0  # yaw\n",
    "            ])\n",
    "            orientations.append(orientation)\n",
    "        \n",
    "        # Generate simple actions\n",
    "        actions = []\n",
    "        for i in range(self.episode_length):\n",
    "            # Simple proportional control\n",
    "            throttle = 0.4 + positions[i][2] * 0.01  # More throttle at altitude\n",
    "            action = np.concatenate([\n",
    "                [throttle, 0.0, 0.0, 0.0],  # flight_control\n",
    "                velocities[i],               # velocity_command\n",
    "                [0.0, 0.0]                  # gimbal\n",
    "            ])\n",
    "            actions.append(action)\n",
    "        \n",
    "        # Create simple state array\n",
    "        states = []\n",
    "        for i in range(self.episode_length):\n",
    "            battery = 100 - i * 0.5  # Battery decreases\n",
    "            gps = np.array([37.7749, -122.4194, positions[i][2]])  # SF coordinates\n",
    "            \n",
    "            state = np.concatenate([\n",
    "                positions[i],     # position (3)\n",
    "                orientations[i],  # orientation (3)\n",
    "                velocities[i],    # velocity (3)\n",
    "                [battery],        # battery (1)\n",
    "                gps              # gps (3)\n",
    "            ])\n",
    "            states.append(state)\n",
    "        \n",
    "        return {\n",
    "            'states': np.array(states),\n",
    "            'actions': np.array(actions),\n",
    "            'positions': np.array(positions)\n",
    "        }\n",
    "    \n",
    "    def save_simple_episode(self, episode_data, episode_idx):\n",
    "        \"\"\"Save episode in minimal LeRobot format.\"\"\"\n",
    "        chunk_dir = self.output_dir / \"data\" / f\"chunk-{episode_idx:03d}\"\n",
    "        chunk_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Save states\n",
    "        obs_df = pd.DataFrame({\n",
    "            'observation.state': [state.tolist() for state in episode_data['states']]\n",
    "        })\n",
    "        obs_df.to_parquet(chunk_dir / \"observation.state.parquet\")\n",
    "        \n",
    "        # Save actions\n",
    "        action_df = pd.DataFrame({\n",
    "            'action': [action.tolist() for action in episode_data['actions']]\n",
    "        })\n",
    "        action_df.to_parquet(chunk_dir / \"action.parquet\")\n",
    "        \n",
    "        print(f\"  ‚úì Episode {episode_idx} data saved\")\n",
    "    \n",
    "    def create_metadata(self, num_episodes):\n",
    "        \"\"\"Create minimal metadata files.\"\"\"\n",
    "        # modality.json\n",
    "        modality = {\n",
    "            \"state\": {\n",
    "                \"position\": {\"start\": 0, \"end\": 3},\n",
    "                \"orientation\": {\"start\": 3, \"end\": 6, \"rotation_type\": \"euler_angles\"},\n",
    "                \"velocity\": {\"start\": 6, \"end\": 9},\n",
    "                \"battery\": {\"start\": 9, \"end\": 10},\n",
    "                \"gps\": {\"start\": 10, \"end\": 13}\n",
    "            },\n",
    "            \"action\": {\n",
    "                \"flight_control\": {\"start\": 0, \"end\": 4},\n",
    "                \"velocity_command\": {\"start\": 4, \"end\": 7},\n",
    "                \"gimbal\": {\"start\": 7, \"end\": 9}\n",
    "            },\n",
    "            \"video\": {\n",
    "                \"front_camera\": {\"original_key\": \"observation.images.front_camera\"},\n",
    "                \"gimbal_camera\": {\"original_key\": \"observation.images.gimbal_camera\"}\n",
    "            },\n",
    "            \"annotation\": {\n",
    "                \"human.task_description\": {\"original_key\": \"task_description\"}\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        with open(self.output_dir / \"meta\" / \"modality.json\", 'w') as f:\n",
    "            json.dump(modality, f, indent=2)\n",
    "        \n",
    "        # info.json\n",
    "        info = {\n",
    "            \"data_name\": \"uav_landing_test\", \n",
    "            \"fps\": self.fps,\n",
    "            \"video\": False  # No video for simple test\n",
    "        }\n",
    "        \n",
    "        with open(self.output_dir / \"meta\" / \"info.json\", 'w') as f:\n",
    "            json.dump(info, f, indent=2)\n",
    "        \n",
    "        # tasks.jsonl\n",
    "        with open(self.output_dir / \"meta\" / \"tasks.jsonl\", 'w') as f:\n",
    "            for i in range(num_episodes):\n",
    "                task = {\"task_index\": i, \"task_description\": \"Land on the designated platform\"}\n",
    "                f.write(json.dumps(task) + '\\n')\n",
    "        \n",
    "        print(\"  ‚úì Metadata files created\")\n",
    "\n",
    "# Generate the test dataset\n",
    "generator = SimpleUAVDataGenerator(dataset_path)\n",
    "\n",
    "print(\"Generating episodes...\")\n",
    "for i in range(num_episodes):\n",
    "    episode_data = generator.generate_simple_episode(i)\n",
    "    generator.save_simple_episode(episode_data, i)\n",
    "\n",
    "generator.create_metadata(num_episodes)\n",
    "\n",
    "print(f\"\\n‚úÖ UAV test dataset generated successfully!\")\n",
    "print(f\"Location: {dataset_path}\")\n",
    "print(f\"Episodes: {num_episodes}\")\n",
    "print(f\"Format: LeRobot compatible\")\n",
    "print(f\"\\nDataset structure:\")\n",
    "print(f\"  üìÅ {dataset_path}/\")\n",
    "print(f\"    üìÅ data/ - Episode data (states, actions)\")\n",
    "print(f\"    üìÅ meta/ - Metadata (modality.json, info.json, tasks.jsonl)\")\n",
    "print(f\"    üìÑ Contains 13D state space and 9D action space\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d2103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loading the generated UAV dataset\n",
    "print(\"üîç Testing Generated UAV Dataset\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    # Load the generated UAV dataset\n",
    "    uav_dataset = LeRobotSingleDataset(\n",
    "        dataset_path=dataset_path,\n",
    "        modality_configs=modality_configs,\n",
    "        embodiment_tag=EmbodimentTag.UAV_QUADCOPTER,\n",
    "        transforms=transforms,\n",
    "        video_backend=\"torchvision_av\",\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Dataset loaded successfully!\")\n",
    "    print(f\"   Episodes: {len(uav_dataset)}\")\n",
    "    print(f\"   Embodiment: {EmbodimentTag.UAV_QUADCOPTER}\")\n",
    "    \n",
    "    # Test accessing data\n",
    "    sample = uav_dataset[0]\n",
    "    print(f\"\\nüìä Sample Data Structure:\")\n",
    "    for key in sorted(sample.keys()):\n",
    "        if hasattr(sample[key], 'shape'):\n",
    "            print(f\"   {key}: shape {sample[key].shape}, dtype {sample[key].dtype}\")\n",
    "        else:\n",
    "            print(f\"   {key}: {type(sample[key])}\")\n",
    "    \n",
    "    # Verify state and action dimensions\n",
    "    print(f\"\\nüî¢ Dimension Verification:\")\n",
    "    \n",
    "    # Check state dimensions (should be 13D)\n",
    "    state_data = sample.get('state', None)\n",
    "    if state_data is not None:\n",
    "        state_shape = state_data.shape[-1] if len(state_data.shape) > 1 else len(state_data)\n",
    "        print(f\"   State dimensions: {state_shape} (expected: 13)\")\n",
    "        if state_shape == 13:\n",
    "            print(\"   ‚úÖ State space correct!\")\n",
    "        else:\n",
    "            print(\"   ‚ùå State space mismatch!\")\n",
    "    \n",
    "    # Check action dimensions (should be 9D)\n",
    "    action_data = sample.get('action', None) \n",
    "    if action_data is not None:\n",
    "        action_shape = action_data.shape[-1] if len(action_data.shape) > 1 else len(action_data)\n",
    "        print(f\"   Action dimensions: {action_shape} (expected: 9)\")\n",
    "        if action_shape == 9:\n",
    "            print(\"   ‚úÖ Action space correct!\")\n",
    "        else:\n",
    "            print(\"   ‚ùå Action space mismatch!\")\n",
    "    \n",
    "    # Test multiple episodes\n",
    "    print(f\"\\nüìà Testing Multiple Episodes:\")\n",
    "    for i in range(min(3, len(uav_dataset))):\n",
    "        episode = uav_dataset[i]\n",
    "        print(f\"   Episode {i}: {len(episode)} keys\")\n",
    "    \n",
    "    print(f\"\\nüéØ Dataset Ready for UAV Training!\")\n",
    "    print(f\"   Use this dataset with:\")\n",
    "    print(f\"   - Fine-tuning: python scripts/uav_finetune.py --data_path {dataset_path}\")\n",
    "    print(f\"   - Evaluation: python getting_started/examples/eval_uav_quadcopter.py\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading dataset: {e}\")\n",
    "    print(\"This might be due to missing dependencies or data format issues\")\n",
    "    print(\"Dataset structure has been created, but full loading may require additional setup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f521ee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test UAV model configuration\n",
    "print(\"ü§ñ Testing UAV Model Configuration\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    from gr00t.model.gr00t_n1 import GR00TN1Policy\n",
    "    from gr00t.experiment.data_config import get_data_config\n",
    "    \n",
    "    # Get UAV data configuration\n",
    "    uav_config = get_data_config(\"uav_quadcopter\")\n",
    "    print(f\"‚úÖ UAV Data Config loaded:\")\n",
    "    print(f\"   State keys: {uav_config.get_state_keys()}\")\n",
    "    print(f\"   Action keys: {uav_config.get_action_keys()}\")\n",
    "    print(f\"   State dim: {uav_config.get_state_dim()}\")\n",
    "    print(f\"   Action dim: {uav_config.get_action_dim()}\")\n",
    "    \n",
    "    # Test model initialization (this would typically require more setup)\n",
    "    print(f\"\\nüîß Model Architecture Info:\")\n",
    "    print(f\"   Action space: {uav_config.get_action_dim()}D\")\n",
    "    print(f\"   State space: {uav_config.get_state_dim()}D\")\n",
    "    print(f\"   Embodiment: {EmbodimentTag.UAV_QUADCOPTER}\")\n",
    "    \n",
    "    # Verify action and state mappings\n",
    "    print(f\"\\nüéØ State-Action Mappings:\")\n",
    "    print(f\"   Position (x,y,z): indices 0-2\")\n",
    "    print(f\"   Orientation (roll,pitch,yaw): indices 3-5\") \n",
    "    print(f\"   Velocity (vx,vy,vz): indices 6-8\")\n",
    "    print(f\"   Battery level: index 9\")\n",
    "    print(f\"   GPS (lat,lon,alt): indices 10-12\")\n",
    "    print(f\"   \")\n",
    "    print(f\"   Flight control (throttle,roll,pitch,yaw): indices 0-3\")\n",
    "    print(f\"   Velocity command (vx,vy,vz): indices 4-6\")\n",
    "    print(f\"   Gimbal control (pan,tilt): indices 7-8\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ UAV Configuration Complete!\")\n",
    "    print(f\"Ready for training with frozen VLM approach:\")\n",
    "    print(f\"  1. VLM backbone: FROZEN (pretrained vision-language understanding)\")\n",
    "    print(f\"  2. Action head: TRAINABLE (UAV-specific diffusion)\")\n",
    "    print(f\"  3. Dataset: LeRobot compatible format\")\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è  Import error: {e}\")\n",
    "    print(\"Some GR00T modules may not be available in this environment\")\n",
    "    print(\"This is expected if running outside the full GR00T environment\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    print(\"Configuration test encountered an issue\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
